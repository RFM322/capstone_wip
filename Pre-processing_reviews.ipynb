{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/generalassembly-open-graph.png\" width=\"240\" height=\"240\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing reviews notebook\n",
    "**Author: Rodolfo Flores Mendez**\n",
    "<br> May 2019 | Chicago, IL.\n",
    "\n",
    "### Table of contents\n",
    "- [Overview](#ov)\n",
    "- [Importing libraries](#imp)\n",
    "- [Feature extraction](#fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview<a id=\"ov\"></a>\n",
    "This notebook contains the code to pre-process the \"review\" dataset in order to extract certain features for modelling purposes. Those features include: \n",
    "\n",
    "    (a) Average rating of \"cool\", \"funny\", and \"useful\" comments,\n",
    "    (b) Average stars/rating per comment,\n",
    "    (d) Total number of positive and negative comments,\n",
    "    (e) Average polarity and subjectivity of comments, \n",
    "    (f) Proxy for a business age,\n",
    "    (g) Time (in days) since last comment, \n",
    "    \n",
    "These features are fed into the \"Data architecture notebook\" along with other features from the \"business\" dataset. The features were summarized by business_id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries<a id=\"imp\"></a>\n",
    "In this section we outline the initial code needed to run this workbook. If this code returns an error we recommend the reader to verify that the most up to date version of the libraries mentioned below have been installed in their computers. For a guideline on python installation of modules please refer to the __[official documentation](https://docs.python.org/3/installing/)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Import regex\n",
    "import regex as re\n",
    "\n",
    "#NLP libraries\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "\n",
    "#Import datetime\n",
    "import datetime as dt\n",
    "\n",
    "#Import Standard Scaler\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction <a id=\"fe\"></a>\n",
    "The following lines of code engineer certain features from the review dataset in order to feed the model.\n",
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function to clean stop words\n",
    "stops=stops = set(stopwords.words('english'))\n",
    "def clean_stops(text):\n",
    "    words=text.split()\n",
    "    words = [w for w in words if not w in stops]\n",
    "    return(\" \".join(words))\n",
    "\n",
    "\n",
    "#Read the review dataframe\n",
    "df = pd.read_csv('./csv_data/review.csv')\n",
    "\n",
    "#Limit the dataframe for only las Vegas (see readme)\n",
    "#Read the numpy array of business IDs pertaining only to las vegas\n",
    "target_ids = np.load('ids.npy')\n",
    "\n",
    "#Convert the business id on a list\n",
    "business_id = df['business_id'].values\n",
    "\n",
    "#Create a mask\n",
    "mask = np.in1d(business_id,target_ids)\n",
    "\n",
    "#Rewrite the dataframe\n",
    "df = df[mask]\n",
    "\n",
    "#Clean the text from special characters\n",
    "df['text'] = df['text'].apply(lambda x: re.sub(r\"[^a-zA-Z]\",\" \",x).lower().strip())\n",
    "df['text'] = df['text'].apply(lambda x: clean_stops(x))\n",
    "\n",
    "\n",
    "#Create a column for the sentiment of each post\n",
    "df['polarity']=df['text'].apply(lambda x: TextBlob(x).sentiment[0])\n",
    "df['subjectivity']=df['text'].apply(lambda x: TextBlob(x).sentiment[1])\n",
    "\n",
    "\n",
    "#Create a column for positive, negative and neutral comments\n",
    "df['positive_negative']=df['polarity'].apply(lambda x: 1 if x>0 else 0)\n",
    "\n",
    "#Convert date to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "#Convert cool to float\n",
    "df['cool'] = df['cool'].astype(float)\n",
    "\n",
    "#Group the dataframe and summarize by business id\n",
    "df_sum = df.groupby('business_id').agg({\n",
    "    'cool': lambda x: np.mean(x),\n",
    "    'funny': lambda x: np.mean(x),\n",
    "    'useful': lambda x: np.mean(x),\n",
    "    'stars': lambda x: np.mean(x),\n",
    "    'polarity': lambda x:np.mean(x),\n",
    "    'subjectivity': lambda x: np.mean(x),\n",
    "    'positive_negative': ['sum',lambda x:len(x)-np.sum(x)],\n",
    "    'date': ['max','min']\n",
    "})\n",
    "\n",
    "#Create a list to rename columns\n",
    "df_sum.columns = [\"_\".join(x).replace(\"_<lambda>\",'') for x in df_sum.columns.ravel()]\n",
    "\n",
    "#Rename columns\n",
    "df_sum.rename(columns = {\n",
    "    'positive_negative_sum':'positive_comments',\n",
    "    'positive_negative':'negative_comments',\n",
    "    'stars':'rev_stars'},\n",
    "             inplace = True)\n",
    "\n",
    "#Create a column for age, time since last comment,\n",
    "df_sum['today'] = pd.to_datetime('today')\n",
    "df_sum['age'] = df_sum['today'] - df_sum['date_min']\n",
    "df_sum['t_last_c'] = df_sum['today'] - df_sum['date_max']\n",
    "df_sum['t_comments'] = df_sum['date_max'] - df_sum['date_min']\n",
    "\n",
    "\n",
    "#Convert date time diffs to ints\n",
    "df_sum['age'] = df_sum['age'] / np.timedelta64(1, 'D')\n",
    "df_sum['t_last_c'] = df_sum['t_last_c'] / np.timedelta64(1, 'D')\n",
    "df_sum['t_comments'] = df_sum['t_comments'] / np.timedelta64(1, 'D')\n",
    "\n",
    "\n",
    "#Standarize all variables to make then closer to the range of -1 and 1\n",
    "minMaxFeat = ['cool','funny','useful','rev_stars']\n",
    "mms = MinMaxScaler()\n",
    "df_mms = mms.fit_transform(df_sum[minMaxFeat])\n",
    "df_mms = pd.DataFrame(df_mms,columns = minMaxFeat)\n",
    "    \n",
    "ssFeat = ['positive_comments','negative_comments','age','t_last_c','t_comments']\n",
    "\n",
    "ss = StandardScaler()\n",
    "df_ss = ss.fit_transform(df_sum[ssFeat])\n",
    "df_ss = pd.DataFrame(df_ss,columns = ssFeat)\n",
    "\n",
    "#Merge all into a final dataframe (excludes polarity and subjectivity)\n",
    "df_fin = pd.concat([df_mms,df_ss,pd.Series(df_sum.index)],axis=1)\n",
    "\n",
    "#Display the head\n",
    "df_fin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29369, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspect the shape\n",
    "df_fin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cool</th>\n",
       "      <th>funny</th>\n",
       "      <th>useful</th>\n",
       "      <th>rev_stars</th>\n",
       "      <th>positive_comments</th>\n",
       "      <th>negative_comments</th>\n",
       "      <th>age</th>\n",
       "      <th>t_last_c</th>\n",
       "      <th>t_comments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>--9e1ONYQuAa-CB_Rrw7Tw</th>\n",
       "      <td>0.025137</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>0.022550</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>7.353262</td>\n",
       "      <td>1.431592</td>\n",
       "      <td>2.596106</td>\n",
       "      <td>-0.612425</td>\n",
       "      <td>2.990671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--DdmeR16TRb3LsjG0ejrQ</th>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.102740</td>\n",
       "      <td>0.063485</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>-0.257236</td>\n",
       "      <td>-0.298266</td>\n",
       "      <td>0.163534</td>\n",
       "      <td>1.568662</td>\n",
       "      <td>-0.759374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--WsruI0IGEoeRmkErU5Gg</th>\n",
       "      <td>0.008824</td>\n",
       "      <td>0.002568</td>\n",
       "      <td>0.010581</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>-0.224003</td>\n",
       "      <td>-0.198466</td>\n",
       "      <td>-1.001078</td>\n",
       "      <td>0.053315</td>\n",
       "      <td>-1.045407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--Y7NhBKzLTbNliMUX_wfg</th>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007054</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>-0.242993</td>\n",
       "      <td>-0.298266</td>\n",
       "      <td>-0.723327</td>\n",
       "      <td>-0.258417</td>\n",
       "      <td>-0.580256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--e8PjCNhEz32pprnPhCwQ</th>\n",
       "      <td>0.010247</td>\n",
       "      <td>0.015908</td>\n",
       "      <td>0.038910</td>\n",
       "      <td>0.508065</td>\n",
       "      <td>-0.176526</td>\n",
       "      <td>-0.032134</td>\n",
       "      <td>-0.347135</td>\n",
       "      <td>-0.523329</td>\n",
       "      <td>-0.043006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            cool     funny    useful  rev_stars  \\\n",
       "business_id                                                       \n",
       "--9e1ONYQuAa-CB_Rrw7Tw  0.025137  0.022688  0.022550   0.781457   \n",
       "--DdmeR16TRb3LsjG0ejrQ  0.082353  0.102740  0.063485   0.583333   \n",
       "--WsruI0IGEoeRmkErU5Gg  0.008824  0.002568  0.010581   0.921875   \n",
       "--Y7NhBKzLTbNliMUX_wfg  0.003922  0.000000  0.007054   0.972222   \n",
       "--e8PjCNhEz32pprnPhCwQ  0.010247  0.015908  0.038910   0.508065   \n",
       "\n",
       "                        positive_comments  negative_comments       age  \\\n",
       "business_id                                                              \n",
       "--9e1ONYQuAa-CB_Rrw7Tw           7.353262           1.431592  2.596106   \n",
       "--DdmeR16TRb3LsjG0ejrQ          -0.257236          -0.298266  0.163534   \n",
       "--WsruI0IGEoeRmkErU5Gg          -0.224003          -0.198466 -1.001078   \n",
       "--Y7NhBKzLTbNliMUX_wfg          -0.242993          -0.298266 -0.723327   \n",
       "--e8PjCNhEz32pprnPhCwQ          -0.176526          -0.032134 -0.347135   \n",
       "\n",
       "                        t_last_c  t_comments  \n",
       "business_id                                   \n",
       "--9e1ONYQuAa-CB_Rrw7Tw -0.612425    2.990671  \n",
       "--DdmeR16TRb3LsjG0ejrQ  1.568662   -0.759374  \n",
       "--WsruI0IGEoeRmkErU5Gg  0.053315   -1.045407  \n",
       "--Y7NhBKzLTbNliMUX_wfg -0.258417   -0.580256  \n",
       "--e8PjCNhEz32pprnPhCwQ -0.523329   -0.043006  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set business id as index\n",
    "df_fin = df_fin.set_index('business_id')\n",
    "\n",
    "#Merge with polarity and subjectivity\n",
    "df_fin =    pd.merge(df_fin,\n",
    "                     df_sum[['polarity','subjectivity']],\n",
    "                     how = 'inner',\n",
    "                     left_index=True,\n",
    "                     right_index=True)\n",
    "\n",
    "#Save df as CSV\n",
    "df_fin.to_csv('./csv_data/reviews_df_vegas.csv')\n",
    "\n",
    "#Display final df head\n",
    "df_fin.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
